---
title: "長庚大學 大數據分析方法 作業三"
output: github_document
---

## 作業說明 （繳交時請直接刪除這個章節）

作業目的：練習初級爬蟲，並將爬蟲結果整理成資料框data.frame

依下列指示，完成網站內文分析：

- 爬取指定網站內容
    - 學號結尾 0,4,8:[Ptt Tech_Job 版](https://www.ptt.cc/bbs/Tech_Job/index.html)
    - 學號結尾 1,5,9:[Ptt NBA 版](https://www.ptt.cc/bbs/NBA/index.html)
    - 學號結尾 2,6:[Ptt LoL 版](https://www.ptt.cc/bbs/LoL/index.html)
    - 學號結尾 3,7:[Ptt movie 版](https://www.ptt.cc/bbs/movie/index.html)
    
- 試著爬出**至少100篇**文章（`30pt`）的**標題**、**推文數**與**作者ID**（各`10pt`）
    - 資料框欄位名稱：
        - **標題**：Title
        - **推文數**：PushNum
        - **作者ID**：Author
    - 一頁只有20篇，該怎麼辦？
        - 提示：使用for + rbind()將分批爬取出的資料結合
        - 範例：dataframeAll<-rbind(dataframe1,dataframe2) 
        - 參考：[6.6 資料組合](http://yijutseng.github.io/DataScienceRBook/manipulation.html#section-6.6)
    
- 將爬取出的資料輸出至Markdown報告中（`10pt`）
    - 使用knitr::kable(資料框物件)整理輸出
    
- 用文字搭配程式碼解釋爬蟲結果 
    - 共爬出幾篇文章標題？（程式碼與文字解釋各`5pt`）
        - dim(), nrow(), str()皆可
    - 哪個作者文章數最多？（程式碼與文字解釋各`5pt`）
        - table()
    - 其他爬蟲結果解釋（`10pt`）
        - 試著找出有趣的現象，不一定要用程式碼搭配解釋，也可只用文字

    

## 網站資料爬取
```{r}
#這是R Code Chunk
library(rvest) ##第一次使用要先安裝 install.packages("rvest")
##read_html
##html_nodes
##html_text
```

## 爬蟲結果呈現
```{r}
#這是R Code Chunk
knitr::kable(iris) ##請將iris取代為上個步驟中產生的爬蟲資料資料框
```

## 解釋爬蟲結果 
```{r}
#這是R Code Chunk
```

解釋解釋解釋解釋

```{r}
#這是R Code Chunk
```

解釋解釋解釋解釋

人工結論與解釋解釋解釋解釋解釋解釋解釋
